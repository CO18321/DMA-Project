<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>DMA Project</title>
  <link rel="stylesheet" href="css/style.css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
 <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>
</head>
<body>

  <div class="mainbody">

       <div class="headblock">
          <span class="headtext">Colorization of Black and White Images using GANs
        </span><br><br>
          <br><br>
          <div class="imgandtxt">
            <div class="box">
              <img class = "photo"  src ="images//deepinder.jpeg" alt="Deepinder Singh" title="Deepinder Singh" ><br>
              <span class="headtext2" >CO18319<br>Deepinder Singh</span>
            </div>
            <div class="box">
              <img class = "photo"  src ="images//ganagsingh.jpg" alt="Ganga Singh" title="Ganga Singh" ><br>
              <span class="headtext2">CO18321<br>Ganga Singh</span>

            </div>
            <div class="box2">
              <img class = "photo"  src ="images//tanveer.jpeg" alt="Tanveer Singh" title="Tanveer Singh" ><br>
              <span class="headtext2">CO18353<br>Tanveer Singh Kochhar</span>

            </div>
          </div>
      </div>

      <div class="content">
          <span class="disc">
          Colorizing black and white pictures is one of the most intriguing uses
          of deep learning. Before the advent of GANs, researchers used vanilla
          neural networks to do this job, but the results were neither realistic nor convincing.
          In 2014, Ian Goodfellow came up with the notion of having two neural networks (Generator and Discriminator)
          fight against each other, similar to how the minimax algorithm works.
          This made the generation of photo-realistic images using neural networks.
          Follow up <span ><a class = "inline_href" href="https://thispersondoesnotexist.com/">thispersondoesnotexist.com</a> </span>
          to get an intuition on the ability of GANs.
          </span><br>
          <span ><img class="imgs" src="images//ig.png" alt="Ian Goodfellow" title="Ian Goodfellow"></span>
          <span class = "img_href">Ian Goodfellow, Father of GANs</span> <br>

      </div>

      <div class="content">
          <br><br><br>
          <span class="heading">Generator & Discriminator</span><br>

          <span class="disc"> <br>The Generator model learns to create a realistic image from input noise,
            and the Discriminator model learns to differentiate between fake and real images.
             The generator's purpose is to deceive the discriminator by providing an image that looks identical to

           the reals. The discriminator's purpose is to estimate how realistic the generated image is.
           Both real and generated (fake) images of the same class are shown to the discriminator to tell the
            difference between the two.
          </span>
            <br>
            <span ><img class="imgs" style="width: 50%; display: block ;margin-left: auto; margin-right: auto"src="images//block_dig.png" alt="Block Diagram of GAN" title="Block Diagram of GAN"></span>
          <span class = "img_href" style="width: 28%;">Block Diagram of GAN</span> <br>


      </div>

      <div class="content">
          <br><br><br>
          <span class="heading">RGB vs L*a*b Color Space</span><br>

          <span class="disc"> <br> After reviewing numerous implementations and studies on image colorization with GANs,
            we discovered that
            the L*a*b color space is preferable to over RGB color space.
            Each pixel in RGB color space has three values that indicate how much
            Red, Green, and Blue it contains.
            The following image shows each channel of RGB color space separately.
          </span>
            <br><br>
            <span ><img class="imgs" src="images//rgb.jpg" alt="Channels in RGB color space" title="Channels in RGB color space"></span>
          <span class = "img_href" style="width: 36%;">Channels in RGB Color Space</span> <br>

          <span class="disc"> <br> Whereas in L*a*b color space each pixel has three numbers.
            The first number (channel), L, encodes the Lightness of each pixel, and it
             appears as a black and white image when visualized. The *a and *b channels represent
              the amount of green-red and yellow-blue in each pixel. The following image shows each
              channel of L*a*b color space separately.

          </span>
            <br><br>
            <span ><img class="imgs" src="images//lab.jpg" alt="Channels in LAB color space" title="Channels in LAB color space"></span>
          <span class = "img_href" style="width: 35%;">Channels in LAB Color Space</span> <br>
          <span class="disc"> <br> To train a colorization model, we first feed it a grayscale

            image and expect that it will colorize it. When we use L*a*b color format we can easily
             pass the L channel, and the model can churn out the other two channels *a and *b.
             Then we concatenate all of the channels to obtain a colorful image. <br><br> However,
             if you use RGB, we'll have to convert the image to grayscale format, feed it to the model,
             and hope it can produce three numbers, which is far more difficult because of many possible
             combinations of three numbers than there are with two. Predicting three numbers for each pixel
             requires choosing between 256 x 256 x 256 alternatives. However, predicting two numbers requires
             choosing between 256 x 256 options.

          </span><br>

      </div>

      <div class="content">
          <br><br><br>
          <span class="heading">Methodology</span><br>

          <span class="disc"> <br>We have used U-Net as the generator of our GAN with a pre-trained ResNet-18 backbone.
             We also pre-trained the generator for 20 epochs in a supervised
            and predetermined way to avoid the problem of "the blind leading the blind".
            The Implemented discriminator model is just a classifier built by stacking the blocks
          of Convolution Layer, BatchNormalization, and LeakyReLU as an activation function to
           determine if the input image is real or false.
         </span>
           <br>
           <span ><img class="imgs" style="width: 50%; display: block ;margin-left: auto; margin-right: auto"src="images//unet.ppm" alt="U-net Architecture" title="U-net Architecture"></span>
         <span class = "img_href" style="width: 23%;">U-net Architecture</span> <br><br>
         <span class="disc">
           To train our model, we used the dataset from <span ><a class = "inline_href" href="https://www.kaggle.com/mariomatos/image-colorization">Kaggle</a> </span> that consisted of 10800 images
            We implemented our code on Google-Colab as it provides access to GPUs.
            The model was trained for 30 epochs with a batch size of 16 to parallelize the data loading.
            The interface for the model is created using gradio module in python

        </span>
        <span ><img class="imgs" src="images//output.png" alt="Interface of our Application" title="Interface of our Application"></span>
        <span class = "img_href" style="width: 34%;">Interface of our Application</span>

      </div>
            <div class="content">
                <br><br><br>
                <span class="heading">Results</span>
                <span class="disc"> <br>The first row represents input black and white images.
                  The second row represents generated colorized images by the trained generator in our GAN,
                  while the third row represents the ground truth for generated images.
               </span><br><br><br>

                <div id="myCarousel" class="carousel slide" data-ride="carousel">
  <!-- Indicators -->
  <ol class="carousel-indicators">
    <li data-target="#myCarousel" data-slide-to="0" class="active"></li>
    <li data-target="#myCarousel" data-slide-to="1"></li>
    <li data-target="#myCarousel" data-slide-to="2"></li>
    <li data-target="#myCarousel" data-slide-to="3"></li>
  </ol>

  <!-- Wrapper for slides -->
  <div class="carousel-inner">
    <div class="item active">
      <img src="images//o1.jpg" alt="1">
    </div>

    <div class="item">
      <img src="images//o2.jpg" alt="2">
    </div>

    <div class="item">
      <img src="images//o3.JPG" alt="3">
    </div>

    <div class="item">
      <img src="images//o4.jpg" alt="4">
    </div>
  </div>

  <!-- Left and right controls -->
  <a class="left carousel-control" href="#myCarousel" data-slide="prev">
    <span class="glyphicon glyphicon-chevron-left"></span>
    <span class="sr-only">Previous</span>
  </a>
  <a class="right carousel-control" href="#myCarousel" data-slide="next">
    <span class="glyphicon glyphicon-chevron-right"></span>
    <span class="sr-only">Next</span>
  </a>
</div>

              </div>

      <div class="content">
          <br><br><br>
          <span class="ref">References</span>
          <br><br>
          <span ><a class = "aref" href="https://towardsdatascience.com/colorizing-black-white-images-with-u-net-and-conditional-gan-a-tutorial-81b2df111cd8">Colorizing black & white images with U-Net and conditional GAN</a> </span>
          <br><br>
          <span ><a class = "aref" href="https://towardsdatascience.com/u-net-deep-learning-colourisation-of-greyscale-images-ee6c1c61aabe">U-Net deep learning colorisation of grayscale images
            </a> </span>
          <br><br>
          <span ><a class = "aref" href="https://arxiv.org/abs/1611.07004">Image-to-Image Translation with Conditional Adversarial Networks</a> </span>
          <br>
      </div>
      <div class="content">
        <br><br>
    </div>

  </div>
  </body>
</html>
